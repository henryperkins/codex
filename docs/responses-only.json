{
  "openapi": "3.0.0",
  "info": {
    "title": "Responses subset (extracted)",
    "version": "v1"
  },
  "components": {
    "schemas": {
      "AzureCreateResponse": {
        "type": "object",
        "required": [
          "model"
        ],
        "properties": {
          "metadata": {
            "type": "object",
            "additionalProperties": {
              "type": "string"
            },
            "description": "Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.",
            "x-oaiTypeLabel": "map"
          },
          "temperature": {
            "type": "number",
            "format": "float",
            "nullable": true,
            "minimum": 0,
            "maximum": 2,
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.",
            "default": 1
          },
          "top_p": {
            "type": "number",
            "format": "float",
            "nullable": true,
            "minimum": 0,
            "maximum": 1,
            "description": "An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.",
            "default": 1
          },
          "user": {
            "type": "string",
            "description": "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)."
          },
          "top_logprobs": {
            "type": "integer",
            "format": "int32",
            "minimum": 0,
            "maximum": 20,
            "description": "An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability."
          },
          "previous_response_id": {
            "type": "string",
            "nullable": true,
            "description": "The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](/docs/guides/conversation-state)."
          },
          "reasoning": {
            "type": "object",
            "allOf": [
              {
                "$ref": "#/components/schemas/OpenAI.Reasoning"
              }
            ],
            "nullable": true
          },
          "background": {
            "type": "boolean",
            "nullable": true,
            "description": "Whether to run the model response in the background.\n[Learn more](/docs/guides/background).",
            "default": false
          },
          "max_output_tokens": {
            "type": "integer",
            "format": "int32",
            "nullable": true,
            "description": "An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning)."
          },
          "max_tool_calls": {
            "type": "integer",
            "format": "int32",
            "nullable": true,
            "description": "The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored."
          },
          "text": {
            "type": "object",
            "properties": {
              "format": {
                "$ref": "#/components/schemas/OpenAI.ResponseTextFormatConfiguration"
              }
            },
            "description": "Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](/docs/guides/text)\n- [Structured Outputs](/docs/guides/structured-outputs)"
          },
          "tools": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/OpenAI.Tool"
            },
            "description": "An array of tools the model may call while generating a response. You \ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model's capabilities, like file search.\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code."
          },
          "tool_choice": {
            "anyOf": [
              {
                "$ref": "#/components/schemas/OpenAI.ToolChoiceOptions"
              },
              {
                "$ref": "#/components/schemas/OpenAI.ToolChoiceObject"
              }
            ],
            "description": "How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call."
          },
          "prompt": {
            "type": "object",
            "allOf": [
              {
                "$ref": "#/components/schemas/OpenAI.Prompt"
              }
            ],
            "nullable": true
          },
          "truncation": {
            "type": "string",
            "enum": [
              "auto",
              "disabled"
            ],
            "nullable": true,
            "description": "The truncation strategy to use for the model response.\n- `auto`: If the context of this response and previous ones exceeds\n  the model's context window size, the model will truncate the\n  response to fit the context window by dropping input items in the\n  middle of the conversation.\n- `disabled` (default): If a model response will exceed the context window\n  size for a model, the request will fail with a 400 error.",
            "default": "disabled"
          },
          "input": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "anyOf": [
                    {
                      "$ref": "#/components/schemas/OpenAI.ImplicitUserMessage"
                    },
                    {
                      "$ref": "#/components/schemas/OpenAI.ItemParam"
                    }
                  ]
                }
              }
            ],
            "description": "Text, image, or file inputs to the model, used to generate a response.\n\nLearn more:\n- [Text inputs and outputs](/docs/guides/text)\n- [Image inputs](/docs/guides/images)\n- [File inputs](/docs/guides/pdf-files)\n- [Conversation state](/docs/guides/conversation-state)\n- [Function calling](/docs/guides/function-calling)"
          },
          "include": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/OpenAI.Includable"
            },
            "nullable": true,
            "description": "Specify additional output data to include in the model response. Currently\nsupported values are:\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution\n  in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of\n  the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n  tokens in reasoning item outputs. This enables reasoning items to be used in\n  multi-turn conversations when using the Responses API statelessly (like\n  when the `store` parameter is set to `false`, or when an organization is\n  enrolled in the zero data retention program)."
          },
          "parallel_tool_calls": {
            "type": "boolean",
            "nullable": true,
            "description": "Whether to allow the model to run tool calls in parallel.",
            "default": true
          },
          "store": {
            "type": "boolean",
            "nullable": true,
            "description": "Whether to store the generated model response for later retrieval via\nAPI.",
            "default": true
          },
          "instructions": {
            "type": "string",
            "nullable": true,
            "description": "A system (or developer) message inserted into the model's context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses."
          },
          "stream": {
            "type": "boolean",
            "nullable": true,
            "description": "If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](/docs/api-reference/responses-streaming)\nfor more information.",
            "default": false
          },
          "model": {
            "type": "string",
            "description": "The model deployment to use for the creation of this response."
          }
        }
      },
      "AzureResponse": {
        "type": "object",
        "required": [
          "metadata",
          "temperature",
          "top_p",
          "user",
          "id",
          "object",
          "created_at",
          "error",
          "incomplete_details",
          "output",
          "instructions",
          "parallel_tool_calls",
          "model"
        ],
        "properties": {
          "metadata": {
            "type": "object",
            "additionalProperties": {
              "type": "string"
            },
            "nullable": true,
            "description": "Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.",
            "x-oaiTypeLabel": "map"
          },
          "temperature": {
            "type": "number",
            "format": "float",
            "nullable": true,
            "minimum": 0,
            "maximum": 2,
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both."
          },
          "top_p": {
            "type": "number",
            "format": "float",
            "nullable": true,
            "minimum": 0,
            "maximum": 1,
            "description": "An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both."
          },
          "user": {
            "type": "string",
            "nullable": true,
            "description": "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids)."
          },
          "top_logprobs": {
            "type": "integer",
            "format": "int32",
            "nullable": true,
            "description": "An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability."
          },
          "previous_response_id": {
            "type": "string",
            "nullable": true,
            "description": "The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](/docs/guides/conversation-state)."
          },
          "reasoning": {
            "type": "object",
            "allOf": [
              {
                "$ref": "#/components/schemas/OpenAI.Reasoning"
              }
            ],
            "nullable": true
          },
          "background": {
            "type": "boolean",
            "nullable": true,
            "description": "Whether to run the model response in the background.\n[Learn more](/docs/guides/background).",
            "default": false
          },
          "max_output_tokens": {
            "type": "integer",
            "format": "int32",
            "nullable": true,
            "description": "An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](/docs/guides/reasoning)."
          },
          "max_tool_calls": {
            "type": "integer",
            "format": "int32",
            "nullable": true,
            "description": "The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored."
          },
          "text": {
            "type": "object",
            "properties": {
              "format": {
                "$ref": "#/components/schemas/OpenAI.ResponseTextFormatConfiguration"
              }
            },
            "description": "Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](/docs/guides/text)\n- [Structured Outputs](/docs/guides/structured-outputs)"
          },
          "tools": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/OpenAI.Tool"
            },
            "description": "An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model's capabilities, like [web search](/docs/guides/tools-web-search)\n  or [file search](/docs/guides/tools-file-search). Learn more about\n  [built-in tools](/docs/guides/tools).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code. Learn more about\n  [function calling](/docs/guides/function-calling)."
          },
          "tool_choice": {
            "anyOf": [
              {
                "$ref": "#/components/schemas/OpenAI.ToolChoiceOptions"
              },
              {
                "$ref": "#/components/schemas/OpenAI.ToolChoiceObject"
              }
            ],
            "description": "How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call."
          },
          "prompt": {
            "type": "object",
            "allOf": [
              {
                "$ref": "#/components/schemas/OpenAI.Prompt"
              }
            ],
            "nullable": true
          },
          "truncation": {
            "type": "string",
            "enum": [
              "auto",
              "disabled"
            ],
            "nullable": true,
            "description": "The truncation strategy to use for the model response.\n- `auto`: If the context of this response and previous ones exceeds\n  the model's context window size, the model will truncate the\n  response to fit the context window by dropping input items in the\n  middle of the conversation.\n- `disabled` (default): If a model response will exceed the context window\n  size for a model, the request will fail with a 400 error.",
            "default": "disabled"
          },
          "id": {
            "type": "string",
            "description": "Unique identifier for this Response."
          },
          "object": {
            "type": "string",
            "enum": [
              "response"
            ],
            "description": "The object type of this resource - always set to `response`."
          },
          "status": {
            "type": "string",
            "enum": [
              "completed",
              "failed",
              "in_progress",
              "cancelled",
              "queued",
              "incomplete"
            ],
            "description": "The status of the response generation. One of `completed`, `failed`,\n`in_progress`, `cancelled`, `queued`, or `incomplete`."
          },
          "created_at": {
            "type": "integer",
            "format": "unixtime",
            "description": "Unix timestamp (in seconds) of when this Response was created."
          },
          "error": {
            "type": "object",
            "allOf": [
              {
                "$ref": "#/components/schemas/OpenAI.ResponseError"
              }
            ],
            "nullable": true
          },
          "incomplete_details": {
            "type": "object",
            "properties": {
              "reason": {
                "type": "string",
                "enum": [
                  "max_output_tokens",
                  "content_filter"
                ],
                "description": "The reason why the response is incomplete."
              }
            },
            "nullable": true,
            "description": "Details about why the response is incomplete."
          },
          "output": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/OpenAI.ItemResource"
            },
            "description": "An array of content items generated by the model.\n\n- The length and order of items in the `output` array is dependent\n  on the model's response.\n- Rather than accessing the first item in the `output` array and\n  assuming it's an `assistant` message with the content generated by\n  the model, you might consider using the `output_text` property where\n  supported in SDKs."
          },
          "instructions": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "$ref": "#/components/schemas/OpenAI.ItemParam"
                }
              }
            ],
            "nullable": true,
            "description": "A system (or developer) message inserted into the model's context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses."
          },
          "output_text": {
            "type": "string",
            "nullable": true,
            "description": "SDK-only convenience property that contains the aggregated text output\nfrom all `output_text` items in the `output` array, if any are present.\nSupported in the Python and JavaScript SDKs."
          },
          "usage": {
            "$ref": "#/components/schemas/OpenAI.ResponseUsage"
          },
          "parallel_tool_calls": {
            "type": "boolean",
            "description": "Whether to allow the model to run tool calls in parallel.",
            "default": true
          },
          "model": {
            "type": "string",
            "description": "The model used to generate this response."
          }
        }
      },
      "OpenAI.ImplicitUserMessage": {
        "type": "object",
        "required": [
          "content"
        ],
        "properties": {
          "content": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "$ref": "#/components/schemas/OpenAI.ItemContent"
                }
              }
            ]
          }
        }
      },
      "OpenAI.Includable": {
        "type": "string",
        "enum": [
          "code_interpreter_call.outputs",
          "computer_call_output.output.image_url",
          "file_search_call.results",
          "message.input_image.image_url",
          "message.output_text.logprobs",
          "reasoning.encrypted_content"
        ],
        "description": "Specify additional output data to include in the model response. Currently\nsupported values are:\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution\n  in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of\n  the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning\n  tokens in reasoning item outputs. This enables reasoning items to be used in\n  multi-turn conversations when using the Responses API statelessly (like\n  when the `store` parameter is set to `false`, or when an organization is\n  enrolled in the zero data retention program)."
      },
      "OpenAI.ItemContent": {
        "type": "object",
        "required": [
          "type"
        ],
        "properties": {
          "type": {
            "$ref": "#/components/schemas/OpenAI.ItemContentType"
          }
        },
        "discriminator": {
          "propertyName": "type",
          "mapping": {
            "input_audio": "#/components/schemas/OpenAI.ItemContentInputAudio",
            "output_audio": "#/components/schemas/OpenAI.ItemContentOutputAudio",
            "refusal": "#/components/schemas/OpenAI.ItemContentRefusal",
            "input_text": "#/components/schemas/OpenAI.ItemContentInputText",
            "input_image": "#/components/schemas/OpenAI.ItemContentInputImage",
            "input_file": "#/components/schemas/OpenAI.ItemContentInputFile",
            "output_text": "#/components/schemas/OpenAI.ItemContentOutputText"
          }
        }
      },
      "OpenAI.ItemContentType": {
        "type": "string",
        "enum": [
          "input_text",
          "input_audio",
          "input_image",
          "input_file",
          "output_text",
          "output_audio",
          "refusal"
        ],
        "description": "Multi-modal input and output contents."
      },
      "OpenAI.ItemParam": {
        "type": "object",
        "required": [
          "type"
        ],
        "properties": {
          "type": {
            "$ref": "#/components/schemas/OpenAI.ItemType"
          }
        },
        "discriminator": {
          "propertyName": "type",
          "mapping": {
            "file_search_call": "#/components/schemas/OpenAI.FileSearchToolCallItemParam",
            "computer_call": "#/components/schemas/OpenAI.ComputerToolCallItemParam",
            "computer_call_output": "#/components/schemas/OpenAI.ComputerToolCallOutputItemParam",
            "web_search_call": "#/components/schemas/OpenAI.WebSearchToolCallItemParam",
            "function_call": "#/components/schemas/OpenAI.FunctionToolCallItemParam",
            "function_call_output": "#/components/schemas/OpenAI.FunctionToolCallOutputItemParam",
            "reasoning": "#/components/schemas/OpenAI.ReasoningItemParam",
            "item_reference": "#/components/schemas/OpenAI.ItemReferenceItemParam",
            "image_generation_call": "#/components/schemas/OpenAI.ImageGenToolCallItemParam",
            "code_interpreter_call": "#/components/schemas/OpenAI.CodeInterpreterToolCallItemParam",
            "local_shell_call": "#/components/schemas/OpenAI.LocalShellToolCallItemParam",
            "local_shell_call_output": "#/components/schemas/OpenAI.LocalShellToolCallOutputItemParam",
            "mcp_list_tools": "#/components/schemas/OpenAI.MCPListToolsItemParam",
            "mcp_approval_request": "#/components/schemas/OpenAI.MCPApprovalRequestItemParam",
            "mcp_approval_response": "#/components/schemas/OpenAI.MCPApprovalResponseItemParam",
            "mcp_call": "#/components/schemas/OpenAI.MCPCallItemParam",
            "message": "#/components/schemas/OpenAI.ResponsesMessageItemParam"
          }
        },
        "description": "Content item used to generate a response."
      },
      "OpenAI.ItemResource": {
        "type": "object",
        "required": [
          "type",
          "id"
        ],
        "properties": {
          "type": {
            "$ref": "#/components/schemas/OpenAI.ItemType"
          },
          "id": {
            "type": "string"
          }
        },
        "discriminator": {
          "propertyName": "type",
          "mapping": {
            "file_search_call": "#/components/schemas/OpenAI.FileSearchToolCallItemResource",
            "computer_call": "#/components/schemas/OpenAI.ComputerToolCallItemResource",
            "computer_call_output": "#/components/schemas/OpenAI.ComputerToolCallOutputItemResource",
            "web_search_call": "#/components/schemas/OpenAI.WebSearchToolCallItemResource",
            "function_call": "#/components/schemas/OpenAI.FunctionToolCallItemResource",
            "function_call_output": "#/components/schemas/OpenAI.FunctionToolCallOutputItemResource",
            "reasoning": "#/components/schemas/OpenAI.ReasoningItemResource",
            "image_generation_call": "#/components/schemas/OpenAI.ImageGenToolCallItemResource",
            "code_interpreter_call": "#/components/schemas/OpenAI.CodeInterpreterToolCallItemResource",
            "local_shell_call": "#/components/schemas/OpenAI.LocalShellToolCallItemResource",
            "local_shell_call_output": "#/components/schemas/OpenAI.LocalShellToolCallOutputItemResource",
            "mcp_list_tools": "#/components/schemas/OpenAI.MCPListToolsItemResource",
            "mcp_approval_request": "#/components/schemas/OpenAI.MCPApprovalRequestItemResource",
            "mcp_approval_response": "#/components/schemas/OpenAI.MCPApprovalResponseItemResource",
            "mcp_call": "#/components/schemas/OpenAI.MCPCallItemResource",
            "message": "#/components/schemas/OpenAI.ResponsesMessageItemResource"
          }
        },
        "description": "Content item used to generate a response."
      },
      "OpenAI.ItemType": {
        "type": "string",
        "enum": [
          "message",
          "file_search_call",
          "function_call",
          "function_call_output",
          "computer_call",
          "computer_call_output",
          "web_search_call",
          "reasoning",
          "item_reference",
          "image_generation_call",
          "code_interpreter_call",
          "local_shell_call",
          "local_shell_call_output",
          "mcp_list_tools",
          "mcp_approval_request",
          "mcp_approval_response",
          "mcp_call"
        ]
      },
      "OpenAI.Prompt": {
        "type": "object",
        "required": [
          "id"
        ],
        "properties": {
          "id": {
            "type": "string",
            "description": "The unique identifier of the prompt template to use."
          },
          "version": {
            "type": "string",
            "nullable": true,
            "description": "Optional version of the prompt template."
          },
          "variables": {
            "type": "object",
            "allOf": [
              {
                "$ref": "#/components/schemas/OpenAI.ResponsePromptVariables"
              }
            ],
            "nullable": true
          }
        },
        "description": "Reference to a prompt template and its variables.\n[Learn more](/docs/guides/text?api-mode=responses#reusable-prompts)."
      },
      "OpenAI.Reasoning": {
        "type": "object",
        "properties": {
          "effort": {
            "allOf": [
              {
                "$ref": "#/components/schemas/OpenAI.ReasoningEffort"
              }
            ],
            "nullable": true,
            "default": "medium"
          },
          "summary": {
            "type": "string",
            "enum": [
              "auto",
              "concise",
              "detailed"
            ],
            "nullable": true,
            "description": "A summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model's reasoning process.\nOne of `auto`, `concise`, or `detailed`."
          },
          "generate_summary": {
            "type": "string",
            "enum": [
              "auto",
              "concise",
              "detailed"
            ],
            "nullable": true,
            "description": "**Deprecated:** use `summary` instead.\n\nA summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model's reasoning process.\nOne of `auto`, `concise`, or `detailed`.",
            "deprecated": true,
            "default": null
          }
        },
        "description": "**o-series models only**\n\nConfiguration options for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning)."
      },
      "OpenAI.ReasoningEffort": {
        "type": "string",
        "enum": [
          "low",
          "medium",
          "high"
        ],
        "description": "**o-series models only**\n\nConstrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response."
      },
      "OpenAI.ResponseError": {
        "type": "object",
        "required": [
          "code",
          "message"
        ],
        "properties": {
          "code": {
            "$ref": "#/components/schemas/OpenAI.ResponseErrorCode"
          },
          "message": {
            "type": "string",
            "description": "A human-readable description of the error."
          }
        },
        "description": "An error object returned when the model fails to generate a Response."
      },
      "OpenAI.ResponseErrorCode": {
        "type": "string",
        "enum": [
          "server_error",
          "rate_limit_exceeded",
          "invalid_prompt",
          "vector_store_timeout",
          "invalid_image",
          "invalid_image_format",
          "invalid_base64_image",
          "invalid_image_url",
          "image_too_large",
          "image_too_small",
          "image_parse_error",
          "image_content_policy_violation",
          "invalid_image_mode",
          "image_file_too_large",
          "unsupported_image_media_type",
          "empty_image_file",
          "failed_to_download_image",
          "image_file_not_found"
        ],
        "description": "The error code for the response."
      },
      "OpenAI.ResponsePromptVariables": {
        "type": "object",
        "additionalProperties": {
          "$ref": "#/components/schemas/OpenAI.ItemParam"
        },
        "description": "Optional map of values to substitute in for variables in your\nprompt. The substitution values can either be strings, or other\nResponse input types like images or files.",
        "x-oaiExpandable": true,
        "x-oaiTypeLabel": "map"
      },
      "OpenAI.ResponseStreamEvent": {
        "type": "object",
        "required": [
          "type",
          "sequence_number"
        ],
        "properties": {
          "type": {
            "$ref": "#/components/schemas/OpenAI.ResponseStreamEventType"
          },
          "sequence_number": {
            "type": "integer",
            "format": "int32",
            "description": "The sequence number for this event."
          }
        },
        "discriminator": {
          "propertyName": "type",
          "mapping": {
            "response.completed": "#/components/schemas/OpenAI.ResponseCompletedEvent",
            "response.content_part.added": "#/components/schemas/OpenAI.ResponseContentPartAddedEvent",
            "response.content_part.done": "#/components/schemas/OpenAI.ResponseContentPartDoneEvent",
            "response.created": "#/components/schemas/OpenAI.ResponseCreatedEvent",
            "error": "#/components/schemas/OpenAI.ResponseErrorEvent",
            "response.file_search_call.completed": "#/components/schemas/OpenAI.ResponseFileSearchCallCompletedEvent",
            "response.file_search_call.in_progress": "#/components/schemas/OpenAI.ResponseFileSearchCallInProgressEvent",
            "response.file_search_call.searching": "#/components/schemas/OpenAI.ResponseFileSearchCallSearchingEvent",
            "response.function_call_arguments.delta": "#/components/schemas/OpenAI.ResponseFunctionCallArgumentsDeltaEvent",
            "response.function_call_arguments.done": "#/components/schemas/OpenAI.ResponseFunctionCallArgumentsDoneEvent",
            "response.in_progress": "#/components/schemas/OpenAI.ResponseInProgressEvent",
            "response.failed": "#/components/schemas/OpenAI.ResponseFailedEvent",
            "response.incomplete": "#/components/schemas/OpenAI.ResponseIncompleteEvent",
            "response.output_item.added": "#/components/schemas/OpenAI.ResponseOutputItemAddedEvent",
            "response.output_item.done": "#/components/schemas/OpenAI.ResponseOutputItemDoneEvent",
            "response.refusal.delta": "#/components/schemas/OpenAI.ResponseRefusalDeltaEvent",
            "response.refusal.done": "#/components/schemas/OpenAI.ResponseRefusalDoneEvent",
            "response.output_text.delta": "#/components/schemas/OpenAI.ResponseTextDeltaEvent",
            "response.output_text.done": "#/components/schemas/OpenAI.ResponseTextDoneEvent",
            "response.reasoning_summary_part.added": "#/components/schemas/OpenAI.ResponseReasoningSummaryPartAddedEvent",
            "response.reasoning_summary_part.done": "#/components/schemas/OpenAI.ResponseReasoningSummaryPartDoneEvent",
            "response.reasoning_summary_text.delta": "#/components/schemas/OpenAI.ResponseReasoningSummaryTextDeltaEvent",
            "response.reasoning_summary_text.done": "#/components/schemas/OpenAI.ResponseReasoningSummaryTextDoneEvent",
            "response.web_search_call.completed": "#/components/schemas/OpenAI.ResponseWebSearchCallCompletedEvent",
            "response.web_search_call.in_progress": "#/components/schemas/OpenAI.ResponseWebSearchCallInProgressEvent",
            "response.web_search_call.searching": "#/components/schemas/OpenAI.ResponseWebSearchCallSearchingEvent",
            "response.image_generation_call.completed": "#/components/schemas/OpenAI.ResponseImageGenCallCompletedEvent",
            "response.image_generation_call.generating": "#/components/schemas/OpenAI.ResponseImageGenCallGeneratingEvent",
            "response.image_generation_call.in_progress": "#/components/schemas/OpenAI.ResponseImageGenCallInProgressEvent",
            "response.image_generation_call.partial_image": "#/components/schemas/OpenAI.ResponseImageGenCallPartialImageEvent",
            "response.mcp_call.arguments_delta": "#/components/schemas/OpenAI.ResponseMCPCallArgumentsDeltaEvent",
            "response.mcp_call.arguments_done": "#/components/schemas/OpenAI.ResponseMCPCallArgumentsDoneEvent",
            "response.mcp_call.completed": "#/components/schemas/OpenAI.ResponseMCPCallCompletedEvent",
            "response.mcp_call.failed": "#/components/schemas/OpenAI.ResponseMCPCallFailedEvent",
            "response.mcp_call.in_progress": "#/components/schemas/OpenAI.ResponseMCPCallInProgressEvent",
            "response.mcp_list_tools.completed": "#/components/schemas/OpenAI.ResponseMCPListToolsCompletedEvent",
            "response.mcp_list_tools.failed": "#/components/schemas/OpenAI.ResponseMCPListToolsFailedEvent",
            "response.mcp_list_tools.in_progress": "#/components/schemas/OpenAI.ResponseMCPListToolsInProgressEvent",
            "response.queued": "#/components/schemas/OpenAI.ResponseQueuedEvent",
            "response.reasoning.delta": "#/components/schemas/OpenAI.ResponseReasoningDeltaEvent",
            "response.reasoning.done": "#/components/schemas/OpenAI.ResponseReasoningDoneEvent",
            "response.reasoning_summary.delta": "#/components/schemas/OpenAI.ResponseReasoningSummaryDeltaEvent",
            "response.reasoning_summary.done": "#/components/schemas/OpenAI.ResponseReasoningSummaryDoneEvent",
            "response.code_interpreter_call_code.delta": "#/components/schemas/OpenAI.ResponseCodeInterpreterCallCodeDeltaEvent",
            "response.code_interpreter_call_code.done": "#/components/schemas/OpenAI.ResponseCodeInterpreterCallCodeDoneEvent",
            "response.code_interpreter_call.completed": "#/components/schemas/OpenAI.ResponseCodeInterpreterCallCompletedEvent",
            "response.code_interpreter_call.in_progress": "#/components/schemas/OpenAI.ResponseCodeInterpreterCallInProgressEvent",
            "response.code_interpreter_call.interpreting": "#/components/schemas/OpenAI.ResponseCodeInterpreterCallInterpretingEvent"
          }
        }
      },
      "OpenAI.ResponseStreamEventType": {
        "anyOf": [
          {
            "type": "string"
          },
          {
            "type": "string",
            "enum": [
              "response.audio.delta",
              "response.audio.done",
              "response.audio_transcript.delta",
              "response.audio_transcript.done",
              "response.code_interpreter_call_code.delta",
              "response.code_interpreter_call_code.done",
              "response.code_interpreter_call.completed",
              "response.code_interpreter_call.in_progress",
              "response.code_interpreter_call.interpreting",
              "response.completed",
              "response.content_part.added",
              "response.content_part.done",
              "response.created",
              "error",
              "response.file_search_call.completed",
              "response.file_search_call.in_progress",
              "response.file_search_call.searching",
              "response.function_call_arguments.delta",
              "response.function_call_arguments.done",
              "response.in_progress",
              "response.failed",
              "response.incomplete",
              "response.output_item.added",
              "response.output_item.done",
              "response.refusal.delta",
              "response.refusal.done",
              "response.output_text.annotation.added",
              "response.output_text.delta",
              "response.output_text.done",
              "response.reasoning_summary_part.added",
              "response.reasoning_summary_part.done",
              "response.reasoning_summary_text.delta",
              "response.reasoning_summary_text.done",
              "response.web_search_call.completed",
              "response.web_search_call.in_progress",
              "response.web_search_call.searching",
              "response.image_generation_call.completed",
              "response.image_generation_call.generating",
              "response.image_generation_call.in_progress",
              "response.image_generation_call.partial_image",
              "response.mcp_call.arguments_delta",
              "response.mcp_call.arguments_done",
              "response.mcp_call.completed",
              "response.mcp_call.failed",
              "response.mcp_call.in_progress",
              "response.mcp_list_tools.completed",
              "response.mcp_list_tools.failed",
              "response.mcp_list_tools.in_progress",
              "response.queued",
              "response.reasoning.delta",
              "response.reasoning.done",
              "response.reasoning_summary.delta",
              "response.reasoning_summary.done"
            ]
          }
        ]
      },
      "OpenAI.ResponseTextFormatConfiguration": {
        "type": "object",
        "required": [
          "type"
        ],
        "properties": {
          "type": {
            "$ref": "#/components/schemas/OpenAI.ResponseTextFormatConfigurationType"
          }
        },
        "discriminator": {
          "propertyName": "type",
          "mapping": {
            "text": "#/components/schemas/OpenAI.ResponseTextFormatConfigurationText",
            "json_object": "#/components/schemas/OpenAI.ResponseTextFormatConfigurationJsonObject",
            "json_schema": "#/components/schemas/OpenAI.ResponseTextFormatConfigurationJsonSchema"
          }
        }
      },
      "OpenAI.ResponseTextFormatConfigurationType": {
        "anyOf": [
          {
            "type": "string"
          },
          {
            "type": "string",
            "enum": [
              "text",
              "json_schema",
              "json_object"
            ]
          }
        ],
        "description": "An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it."
      },
      "OpenAI.ResponseUsage": {
        "type": "object",
        "required": [
          "input_tokens",
          "input_tokens_details",
          "output_tokens",
          "output_tokens_details",
          "total_tokens"
        ],
        "properties": {
          "input_tokens": {
            "type": "integer",
            "format": "int32",
            "description": "The number of input tokens."
          },
          "input_tokens_details": {
            "type": "object",
            "properties": {
              "cached_tokens": {
                "type": "integer",
                "format": "int32",
                "description": "The number of tokens that were retrieved from the cache.\n[More on prompt caching](/docs/guides/prompt-caching)."
              }
            },
            "required": [
              "cached_tokens"
            ],
            "description": "A detailed breakdown of the input tokens."
          },
          "output_tokens": {
            "type": "integer",
            "format": "int32",
            "description": "The number of output tokens."
          },
          "output_tokens_details": {
            "type": "object",
            "properties": {
              "reasoning_tokens": {
                "type": "integer",
                "format": "int32",
                "description": "The number of reasoning tokens."
              }
            },
            "required": [
              "reasoning_tokens"
            ],
            "description": "A detailed breakdown of the output tokens."
          },
          "total_tokens": {
            "type": "integer",
            "format": "int32",
            "description": "The total number of tokens used."
          }
        },
        "description": "Represents token usage details including input tokens, output tokens,\na breakdown of output tokens, and the total tokens used."
      },
      "OpenAI.Tool": {
        "type": "object",
        "required": [
          "type"
        ],
        "properties": {
          "type": {
            "$ref": "#/components/schemas/OpenAI.ToolType"
          }
        },
        "discriminator": {
          "propertyName": "type",
          "mapping": {
            "function": "#/components/schemas/OpenAI.FunctionTool",
            "file_search": "#/components/schemas/OpenAI.FileSearchTool",
            "computer_use_preview": "#/components/schemas/OpenAI.ComputerUsePreviewTool",
            "web_search_preview": "#/components/schemas/OpenAI.WebSearchPreviewTool",
            "code_interpreter": "#/components/schemas/OpenAI.CodeInterpreterTool",
            "image_generation": "#/components/schemas/OpenAI.ImageGenTool",
            "local_shell": "#/components/schemas/OpenAI.LocalShellTool",
            "mcp": "#/components/schemas/OpenAI.MCPTool"
          }
        }
      },
      "OpenAI.ToolChoiceObject": {
        "type": "object",
        "required": [
          "type"
        ],
        "properties": {
          "type": {
            "$ref": "#/components/schemas/OpenAI.ToolChoiceObjectType"
          }
        },
        "discriminator": {
          "propertyName": "type",
          "mapping": {
            "file_search": "#/components/schemas/OpenAI.ToolChoiceObjectFileSearch",
            "computer_use_preview": "#/components/schemas/OpenAI.ToolChoiceObjectComputer",
            "web_search_preview": "#/components/schemas/OpenAI.ToolChoiceObjectWebSearch",
            "image_generation": "#/components/schemas/OpenAI.ToolChoiceObjectImageGen",
            "code_interpreter": "#/components/schemas/OpenAI.ToolChoiceObjectCodeInterpreter",
            "function": "#/components/schemas/OpenAI.ToolChoiceObjectFunction",
            "mcp": "#/components/schemas/OpenAI.ToolChoiceObjectMCP"
          }
        }
      },
      "OpenAI.ToolChoiceObjectType": {
        "anyOf": [
          {
            "type": "string"
          },
          {
            "type": "string",
            "enum": [
              "file_search",
              "function",
              "computer_use_preview",
              "web_search_preview",
              "image_generation",
              "code_interpreter",
              "mcp"
            ]
          }
        ],
        "description": "Indicates that the model should use a built-in tool to generate a response.\n[Learn more about built-in tools](/docs/guides/tools)."
      },
      "OpenAI.ToolChoiceOptions": {
        "type": "string",
        "enum": [
          "none",
          "auto",
          "required"
        ],
        "description": "Controls which (if any) tool is called by the model.\n\n`none` means the model will not call any tool and instead generates a message.\n\n`auto` means the model can pick between generating a message or calling one or\nmore tools.\n\n`required` means the model must call one or more tools."
      },
      "OpenAI.ToolType": {
        "anyOf": [
          {
            "type": "string"
          },
          {
            "type": "string",
            "enum": [
              "file_search",
              "function",
              "computer_use_preview",
              "web_search_preview",
              "mcp",
              "code_interpreter",
              "image_generation",
              "local_shell"
            ]
          }
        ],
        "description": "A tool that can be used to generate a response."
      }
    }
  }
}
